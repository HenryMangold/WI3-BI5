{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T18:07:08.416786Z",
     "start_time": "2021-11-22T18:07:08.166783Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Daten Einlesen</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T18:07:10.679732Z",
     "start_time": "2021-11-22T18:07:08.418786Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accelerometer_x': array([-7.2265625, -7.1679688, -7.1679688, ..., -7.084961 , -7.084961 ,\n",
      "       -7.1679688], dtype=float32), 'accelerometer_y': array([6.850586, 6.801758, 6.801758, ..., 6.821289, 6.821289, 6.928711],\n",
      "      dtype=float32), 'accelerometer_z': array([0.9082031 , 0.7861328 , 0.7861328 , ..., 0.8496094 , 0.8496094 ,\n",
      "       0.88378906], dtype=float32), 'magnetometer_x': array([-53937500., -53937500., -53937500., ..., -51750000., -51750000.,\n",
      "       -54312500.], dtype=float32), 'magnetometer_y': array([4062500., 4062500., 4062500., ..., 3750000., 3750000., 3750000.],\n",
      "      dtype=float32), 'magnetometer_z': array([-5937500., -5937500., -5937500., ..., -6000000., -6000000.,\n",
      "       -4812500.], dtype=float32), 'audio': array([0.00872803, 0.0083313 , 0.00796509, ..., 0.0163269 , 0.0163269 ,\n",
      "       0.01504517], dtype=float32), 'timer': array([       0,        1,        1, ..., 86277649, 86277650, 86277650],\n",
      "      dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "unpickled_df = pd.read_pickle(\"../Data/data_inside_20211012_000102.pkl\")\n",
    "\n",
    "print(unpickled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T18:07:10.814058Z",
     "start_time": "2021-11-22T18:07:10.681448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86277650\n"
     ]
    }
   ],
   "source": [
    "print(unpickled_df['timer'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Audio Step für Smoothing festlegen</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T18:07:10.818425Z",
     "start_time": "2021-11-22T18:07:10.815749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio steps: 105\n"
     ]
    }
   ],
   "source": [
    "# to 20Hz\n",
    "# Calculation:   audio_step  =  2100d/s  /  20Hz  =  105s\n",
    "\n",
    "audio_step = int(2100 / 20) \n",
    "\n",
    "print('audio steps:', audio_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Indizes für den Split der Sensor Dateien finden</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-22T18:09:30.761Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_no_audio = {}\n",
    "for k in unpickled_df.keys():\n",
    "    if k != 'audio':\n",
    "        dict_no_audio[k] = unpickled_df[k]\n",
    "     \n",
    "print(dict_no_audio['accelerometer_x'].size, ' / ', dict_no_audio['magnetometer_x'].size, ' / ', dict_no_audio['timer'].size)\n",
    "############################################\n",
    "# das hier ist ist hoffentlich nur für das 1h example notwendig\n",
    "#dict_no_audio['timer'] = np.append(dict_no_audio['timer'], 3599906)\n",
    "#print('after append: ', dict_no_audio['accelerometer_x'].size, ' / ', dict_no_audio['magnetometer_x'].size, ' / ', dict_no_audio['timer'].size)\n",
    "############################################\n",
    "\n",
    "df_no_audio = pd.DataFrame(dict_no_audio)\n",
    "df_no_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T18:13:40.121094Z",
     "start_time": "2021-11-22T18:13:39.822190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      49       99      149 ... 86277549 86277599 86277649]\n",
      "1725553\n"
     ]
    }
   ],
   "source": [
    "# range von timer values an denen aufgeteilt werden muss\n",
    "# enthält immer die letzte ms die in einem Step sein soll\n",
    "val_range = np.array(range(49,unpickled_df['timer'].max(),50))\n",
    "print (val_range)\n",
    "print (val_range.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-22T18:07:08.116Z"
    }
   },
   "outputs": [],
   "source": [
    "# für jede ms in val_range den index der folgenden ms bestimmen (dieser index wird in der split funktion später gebraucht)\n",
    "i_split_arr = []\n",
    "i = 0\n",
    "for ms in val_range:\n",
    "    i_split_arr.append(dict_no_audio['timer'].searchsorted(ms, side='right'))\n",
    "#print(i_split_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-22T18:07:08.120Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(i_split_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/41255215/pandas-find-first-occurrence\n",
    "\n",
    "numpy searchsorted bei hourly example: ~100ms - warum dauert es hier so viel länger?\n",
    "  - Lenge des 'i_split_arr' nach 58m und keyboard interupt sind ~16k einträge. Das 'hour example' hat 72k einträge in ~100ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-22T18:07:08.122Z"
    }
   },
   "outputs": [],
   "source": [
    "# überprüfen ob der richtige Index für den entsprechende Timer Wert gefunden wurde\n",
    "# bei timer sollte 50 stehen (50ms == 1/20sec)\n",
    "df_no_audio.iloc[i_split_arr[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-22T18:07:08.126Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################### nach MS ################################################\n",
    "# erstellen eines leeren dictionaries\n",
    "smt_dict = {}\n",
    "\n",
    "for variable in unpickled_df.keys():\n",
    "    if \"accelerometer\" in variable:\n",
    "        # Array wird anhand der Indizes der MS gesplittet, mit NaN values auf die selbe lenge gebracht und gestacked\n",
    "        ac_split_arr = np.split(unpickled_df[variable], i_split_arr)\n",
    "        pad = len(max(ac_split_arr, key=len))\n",
    "        pad_ac_split_arr = np.array([np.append(i, [[np.nan]*(pad-len(i))]) for i in ac_split_arr])\n",
    "        stack_ac_split_arr = np.vstack(pad_ac_split_arr)\n",
    "        \n",
    "        # Zusammenfassen und in dictionary schreiben, NaN values werden ignoriert\n",
    "        # maximum\n",
    "        smt_dict[variable+'_max'] = np.nanmax(stack_ac_split_arr, axis = 1)\n",
    "        # 95% quantile\n",
    "        smt_dict[variable+'_95q'] = np.nanquantile(stack_ac_split_arr, 0.95, axis = 1)\n",
    "        # minimum\n",
    "        smt_dict[variable+'_min'] = np.nanmin(stack_ac_split_arr, axis = 1)\n",
    "        # 5% quantile\n",
    "        smt_dict[variable+'_05q'] = np.nanquantile(stack_ac_split_arr, 0.05, axis = 1)\n",
    "        \n",
    "    elif \"magnetometer\" in variable:\n",
    "        # Array wird anhand der Indizes der MS gesplittet, mit NaN values auf die selbe lenge gebracht und gestacked\n",
    "        ma_split_arr = np.split(unpickled_df[variable], i_split_arr)\n",
    "        pad = len(max(ma_split_arr, key=len))\n",
    "        pad_ma_split_arr = np.array([np.append(i, [[np.nan]*(pad-len(i))]) for i in ma_split_arr])\n",
    "        stack_ma_split_arr = np.vstack(pad_ma_split_arr)\n",
    "        \n",
    "        # Zusammenfassen und in dictionary schreiben, NaN values werden ignoriert\n",
    "        # mean\n",
    "        smt_dict[variable+'_mean'] = np.nanmean(stack_ma_split_arr, axis = 1)\n",
    "        # median\n",
    "        smt_dict[variable+'_med'] = np.nanmedian(stack_ma_split_arr, axis = 1)\n",
    "        \n",
    "    elif \"audio\" in variable:\n",
    "        au_split_arr = np.vstack(np.split(unpickled_df[variable], range(audio_step, unpickled_df['audio'].size, audio_step))[:-1])\n",
    "        \n",
    "        # Zusammenfassen und in DataFrame schreiben, NaN values werden ignoriert\n",
    "        # maximum\n",
    "        smt_dict[variable+'_max'] = np.amax(au_split_arr, axis = 1)\n",
    "        # 95% quantile\n",
    "        smt_dict[variable+'_95q'] = np.quantile(au_split_arr, 0.95, axis = 1)\n",
    "\n",
    "        \n",
    "print('sensor ', smt_dict['accelerometer_x_max'].size)\n",
    "print('audio ', smt_dict['audio_max'].size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
