{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T14:24:17.332933Z",
     "start_time": "2021-11-29T14:24:17.329531Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define functions for pipeline</h1>\n",
    "<h2>Find start timestamp</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T20:14:31.532827Z",
     "start_time": "2021-11-28T20:14:31.528506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 00:01:02.001000\n"
     ]
    }
   ],
   "source": [
    "def find_start_date(filename=str):\n",
    "    match = re.search(r'\\d{4}\\d{2}\\d{2}_\\d{2}\\d{2}\\d{2}', filename)\n",
    "    date = datetime.datetime.strptime(match.group(), '%Y%m%d_%H%M%S')\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define cutting points</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T20:25:54.996297Z",
     "start_time": "2021-11-28T20:25:54.987589Z"
    }
   },
   "outputs": [],
   "source": [
    "def cutting_points(unpickled):\n",
    "    # create dataframe without audio records for split-steps von\n",
    "    dict_no_audio = {}\n",
    "    for k in unpickled.keys():\n",
    "        if k != 'audio':\n",
    "            dict_no_audio[k] = unpickled[k]\n",
    "\n",
    "    #################### f√ºr 1h example ########################\n",
    "    dict_no_audio['timer'] = np.append(dict_no_audio['timer'], 3599906)\n",
    "    ############################################################\n",
    "    \n",
    "    # define range for split-steps of sensor records\n",
    "    val_range = np.array(range(49,unpickled['timer'].max(),50))\n",
    "    \n",
    "    # split-steps of sensor records\n",
    "    i_split_arr = []\n",
    "\n",
    "    for ms in val_range:\n",
    "        i_split_arr.append(dict_no_audio['timer'].searchsorted(ms, side='right'))\n",
    "    \n",
    "    # split-step of audio records\n",
    "    step = int(2100 / 20)\n",
    "\n",
    "    return i_split_arr, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalized accelerometer/magnetometer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T20:14:31.602904Z",
     "start_time": "2021-11-28T20:14:31.551017Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_normalized_sensors(unpickled):\n",
    "    # calculate vektor length of sensors\n",
    "    unpickled['accelerometer'] = (unpickled['accelerometer_x']**2 + unpickled['accelerometer_y']**2 + unpickled['accelerometer_z']**2)**0.5\n",
    "    unpickled['magnetometer'] = (unpickled['magnetometer_x']**2 + unpickled['magnetometer_y']**2 + unpickled['magnetometer_z']**2)**0.5\n",
    "    return unpickled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Split and claculate values for 20 Hz</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T20:34:03.149185Z",
     "start_time": "2021-11-28T20:34:03.134646Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def smoothing(unpickled, i_split_arr, step):\n",
    "    # create dictionary with records (run split) & calculate min/max/quantil\n",
    "\n",
    "    smt_dict = {}\n",
    "\n",
    "    for variable in unpickled.keys():\n",
    "        if \"accelerometer\" in variable:\n",
    "            # Array wird anhand der Indizes der MS gesplittet, mit NaN values auf die selbe lenge gebracht und gestacked\n",
    "            ac_split_arr = np.split(unpickled[variable], i_split_arr)\n",
    "            pad = len(max(ac_split_arr, key=len))\n",
    "            pad_ac_split_arr = np.array([np.append(i, [[np.nan]*(pad-len(i))]) for i in ac_split_arr])\n",
    "            stack_ac_split_arr = np.vstack(pad_ac_split_arr)\n",
    "\n",
    "            # Zusammenfassen und in dictionary schreiben, NaN values werden ignoriert\n",
    "            # maximum\n",
    "            smt_dict[variable+'_max'] = np.nanmax(stack_ac_split_arr, axis = 1)\n",
    "            # 95% quantile\n",
    "            smt_dict[variable+'_95q'] = np.nanquantile(stack_ac_split_arr, 0.95, axis = 1)\n",
    "            # minimum\n",
    "            smt_dict[variable+'_min'] = np.nanmin(stack_ac_split_arr, axis = 1)\n",
    "            # 5% quantile\n",
    "            smt_dict[variable+'_05q'] = np.nanquantile(stack_ac_split_arr, 0.05, axis = 1)\n",
    "\n",
    "        elif \"magnetometer\" in variable:\n",
    "            # Array wird anhand der Indizes der MS gesplittet, mit NaN values auf die selbe lenge gebracht und gestacked\n",
    "            ma_split_arr = np.split(unpickled[variable], i_split_arr)\n",
    "            pad = len(max(ma_split_arr, key=len))\n",
    "            pad_ma_split_arr = np.array([np.append(i, [[np.nan]*(pad-len(i))]) for i in ma_split_arr])\n",
    "            stack_ma_split_arr = np.vstack(pad_ma_split_arr)\n",
    "\n",
    "            # Zusammenfassen und in dictionary schreiben, NaN values werden ignoriert\n",
    "            # mean\n",
    "            smt_dict[variable+'_mean'] = np.nanmean(stack_ma_split_arr, axis = 1)\n",
    "            # median\n",
    "            smt_dict[variable+'_med'] = np.nanmedian(stack_ma_split_arr, axis = 1)\n",
    "\n",
    "        elif \"audio\" in variable:\n",
    "            au_split_arr = np.vstack(np.split(unpickled[variable], range(step, unpickled['audio'].size, step)))\n",
    "\n",
    "            # Zusammenfassen und in DataFrame schreiben, NaN values werden ignoriert\n",
    "            # maximum\n",
    "            smt_dict[variable+'_max'] = np.amax(au_split_arr, axis = 1)\n",
    "\n",
    "            # 95% quantile\n",
    "            smt_dict[variable+'_95q'] = np.quantile(au_split_arr, 0.95, axis = 1)\n",
    "        \n",
    "        elif \"timer\" in variable:\n",
    "            smt_dict[variable] = np.array(range(0,unpickled['timer'].max(),50))\n",
    "            if unpickled['timer'].max()%50:\n",
    "                smt_dict[variable] = np.append(smt_dict[variable],(smt_dict[variable].max()+1))\n",
    "            \n",
    "    return smt_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T00:11:07.951420Z",
     "start_time": "2021-11-25T00:11:07.939193Z"
    }
   },
   "source": [
    "<b>DataFrame erstellen</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T20:15:54.652066Z",
     "start_time": "2021-11-28T20:15:54.569388Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smt_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/user/1019/ipykernel_27051/4240771602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mperform_equality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/user/1019/ipykernel_27051/4240771602.py\u001b[0m in \u001b[0;36mperform_equality\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# determine difference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msmt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msmt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accelerometer_x_max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# more audio records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smt_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# perform equality of sensor & audio records\n",
    "def perform_equality():\n",
    "    \n",
    "    # determine difference\n",
    "    diff = (smt_dict['audio_max'].size - smt_dict['accelerometer_x_max'].size)\n",
    "    \n",
    "    # more audio records\n",
    "    if diff > 0: \n",
    "        \n",
    "        # trim records under consideration of difference\n",
    "        smt_dict['audio_max'] = smt_dict['audio_max'][0:smt_dict['audio_max'].size-diff]\n",
    "        smt_dict['audio_95q'] = smt_dict['audio_95q'][0:smt_dict['audio_95q'].size-diff]\n",
    "        \n",
    "        # determine number of sensor records\n",
    "        for key in smt_dict.keys():\n",
    "            print (key, ': ', smt_dict[key].size)\n",
    "        \n",
    "    # more sensor records\n",
    "    elif diff < 0: \n",
    "        return \"NotImplementedError :D\"\n",
    "    \n",
    "    # equal number of audio & sensor records\n",
    "    elif diff == 0:\n",
    "        return \"Equality is given\"\n",
    "\n",
    "\n",
    "perform_equality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T20:14:31.636991Z",
     "start_time": "2021-11-28T20:14:31.636963Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataframe \n",
    "df = pd.DataFrame.from_dict(smt_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Export als Pickle-File {temporary}</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T20:14:31.639242Z",
     "start_time": "2021-11-28T20:14:31.639213Z"
    }
   },
   "outputs": [],
   "source": [
    "# export dataframe as pickle-file\n",
    "now = datetime.now()\n",
    "date = now.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "df.to_pickle(\"./export_\" + str(date) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Find files in directory and start smoothing pipeline</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T20:34:59.994982Z",
     "start_time": "2021-11-28T20:34:08.475843Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/user/1019/ipykernel_27051/2052647417.py:16: RuntimeWarning: All-NaN slice encountered\n",
      "  smt_dict[variable+'_max'] = np.nanmax(stack_ac_split_arr, axis = 1)\n",
      "/home/bi5/anaconda3/envs/python3/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1395: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/tmp/user/1019/ipykernel_27051/2052647417.py:20: RuntimeWarning: All-NaN slice encountered\n",
      "  smt_dict[variable+'_min'] = np.nanmin(stack_ac_split_arr, axis = 1)\n",
      "/tmp/user/1019/ipykernel_27051/2052647417.py:33: RuntimeWarning: Mean of empty slice\n",
      "  smt_dict[variable+'_mean'] = np.nanmean(stack_ma_split_arr, axis = 1)\n",
      "/home/bi5/anaconda3/envs/python3/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1119: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accelerometer_x_max': array([-7.01660156, -7.03125   , -7.02636719, ..., -6.93847656,\n",
      "       -6.95800781, -7.06054688]), 'accelerometer_x_95q': array([-7.01733398, -7.04589844, -7.04101562, ..., -6.99291992,\n",
      "       -6.98730469, -7.06054688]), 'accelerometer_x_min': array([-7.13378906, -7.14355469, -7.17285156, ..., -7.15820312,\n",
      "       -7.20214844, -7.15820312]), 'accelerometer_x_05q': array([-7.11914062, -7.13378906, -7.14355469, ..., -7.15332031,\n",
      "       -7.17138672, -7.15820312]), 'accelerometer_y_max': array([7.00683594, 7.00195312, 6.99707031, ..., 7.05078125, 7.09472656,\n",
      "       6.94824219]), 'accelerometer_y_95q': array([7.0065918 , 6.99194336, 6.9921875 , ..., 7.01660156, 7.03540039,\n",
      "       6.94824219]), 'accelerometer_y_min': array([6.90429688, 6.90917969, 6.92382812, ..., 6.74804688, 6.79199219,\n",
      "       6.81640625]), 'accelerometer_y_05q': array([6.92871094, 6.92407227, 6.92944336, ..., 6.84570312, 6.81713867,\n",
      "       6.85302734]), 'accelerometer_z_max': array([0.81054688, 0.84960938, 0.8203125 , ..., 0.91796875, 0.83007812,\n",
      "       0.81542969]), 'accelerometer_z_95q': array([0.79101562, 0.8203125 , 0.8203125 , ..., 0.85449219, 0.80493164,\n",
      "       0.81542969]), 'accelerometer_z_min': array([0.703125  , 0.69335938, 0.69824219, ..., 0.65917969, 0.69335938,\n",
      "       0.7421875 ]), 'accelerometer_z_05q': array([0.71289062, 0.71777344, 0.703125  , ..., 0.69824219, 0.71289062,\n",
      "       0.75317383]), 'magnetometer_x_mean': array([-52647671.56862745, -52560049.01960784, -51442307.6923077 , ...,\n",
      "       -51797181.37254902, -52557692.3076923 , -52738281.25      ]), 'magnetometer_x_med': array([-53000000., -52250000., -51500000., ..., -52000000., -53062500.,\n",
      "       -53437500.]), 'magnetometer_y_mean': array([1120710.78431373, 1757965.68627451,  277043.26923077, ...,\n",
      "       2688112.74509804, 2802283.65384615, 1078125.        ]), 'magnetometer_y_med': array([1125000., 1500000.,       0., ..., 2250000., 3000000.,  750000.]), 'magnetometer_z_mean': array([-2818014.70588235, -4245098.03921569, -3405649.03846154, ...,\n",
      "       -4427696.07843137, -4545072.11538462, -5789062.5       ]), 'magnetometer_z_med': array([-3062500., -4625000., -3062500., ..., -3875000., -4312500.,\n",
      "       -5875000.]), 'audio_max': array([0.00787354, 0.00927734, 0.00772095, ..., 0.02108765, 0.03695679,\n",
      "       0.0291748 ], dtype=float32), 'audio_95q': array([0.00689697, 0.00614014, 0.00629883, ..., 0.01790771, 0.024823  ,\n",
      "       0.02116699]), 'timer': array([      0,      50,     100, ..., 3599850, 3599900, 3599901]), 'accelerometer_max': array([10.01143551, 10.01541615, 10.01549244, ..., 10.05514908,\n",
      "       10.08987331, 10.00264263]), 'accelerometer_95q': array([10.00666132, 10.01104927, 10.00113487, ..., 10.04667091,\n",
      "       10.06176186, 10.00264263]), 'accelerometer_min': array([9.88150883, 9.91287899, 9.91214657, ..., 9.75542545, 9.78453445,\n",
      "       9.84202957]), 'accelerometer_05q': array([9.8988513 , 9.92150116, 9.91736712, ..., 9.77875805, 9.81223011,\n",
      "       9.88075781]), 'magnetometer_mean': array([52834591.7254902 , 52837707.25490196, 51619339.6923077 , ...,\n",
      "       52110956.5882353 , 52884512.57692308, 53076904.        ]), 'magnetometer_med': array([53121508., 52583748., 51523204., ..., 52306228., 53139004.,\n",
      "       53792172.])}\n"
     ]
    }
   ],
   "source": [
    "data_inside = []\n",
    "data_outside = []\n",
    "\n",
    "for path, currentDirectory, files in os.walk(\"../WI3_BusinessIntelligence_Data/\"):\n",
    "    for file in files:\n",
    "        if file.startswith(\"data_inside_\") and file.endswith('_one_hour_example.pkl'):\n",
    "            unpickled = pd.read_pickle(path+file)\n",
    "            # find starting time of recording\n",
    "            start_time = find_start_date(file)\n",
    "            # find indices/step size for smoothing\n",
    "            i_split_arr, step = cutting_points(unpickled)\n",
    "            # optional: add normalized vectors for sensors to data\n",
    "            unpickled = add_normalized_sensors(unpickled)\n",
    "            # split and calculate values for 20 Hz\n",
    "            smt_dict = smoothing(unpickled, i_split_arr, step)\n",
    "            print(smt_dict)\n",
    "        #elif file.startswith(\"data_outside_\") and file.endswith('_one_hour_example.pkl'):\n",
    "            #unpickled = pd.read_pickle(path+file)\n",
    "            #start_time = find_start_date(file)\n",
    "            #print(start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
